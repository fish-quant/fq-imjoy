<docs lang="markdown">
Python plugin performing analyze of smFISH images. 
</docs>

<config lang="json">
{
  "name": "FQ-worker",
  "type": "native-python",
  "version": "0.0.1",
  "description": "Worker to process smFISH images.",
  "tags": ["stable","dev"],
  "ui": "",
  "cover": "",
  "inputs": null,
  "outputs": null,
  "flags": ["single-instance", "allow-detach"],
  "icon": "extension",
  "api_version": "0.1.7",
  "env": "",
  "permissions": [],
  "requirements": { "stable":["pip: -U git+https://github.com/fish-quant/big-fish@prepare_v1"],
                    "dev": ["pip: --editable D:\\Documents\\code\\GitHub\\projects\\big-fish"]},
  "dependencies": [],
  "runnable": false
}
</config>

<script lang="python">
from imjoy import api

import asyncio
import sys
import os
from pathlib import Path
import json
import re
import base64

import numpy as np
from skimage import io
import pandas as pd
from skimage.exposure import rescale_intensity

if sys.platform == "darwin":
    import matplotlib
    matplotlib.use('PS')

api.log(' >>>> SYS PATH:')
api.log(sys.path)

from bigfish import stack, plot, detection

def create_folder(path_new):
    """
    Check if path `path_new` exisist. If not, create it.
    """
    if not path_new.is_dir():
        path_new.mkdir(parents=True)


def create_output_path(data_path, output_path):
    """
    Function to determine correct output path.

    If the string output_path contains characters '>>' it will not
    be interpreted as a path name but as an indicator for a string
    replacement operation for the data_path: old_str>>new_str
    """
    
    # Make sure they are strings
    data_path = str(data_path)
    output_path = str(output_path)

    if (re.search(">>", output_path)):
      str_orig = re.search(r'^(.*)>>(.*)$', output_path).group(1)
      str_rep = re.search(r'^(.*)>>(.*)$', output_path).group(2)

      print(f'Replacement parameters found: original string: {str_orig}, replacement string: {str_rep}')

      output_path_return = data_path.replace(str_orig,str_rep)
      print(f'Output path: {output_path_return}')

    else:
      print("No match")
      output_path_return = output_path

    # Convert back to Path
    output_path_return = Path(output_path_return)
    create_folder(output_path_return)

    return output_path_return


async def image_mip_url(img, name_save, file_manager, rescale=True):
    """
    Provide a base64 encoded URL of a MIP.
    """
    img_MIP = stack.maximum_projection(img)

    if rescale:
        pa, pb = np.percentile(img_MIP, (0.1,99.9))
        img_MIP = rescale_intensity(img_MIP, in_range=(pa, pb),out_range=np.uint8).astype('uint8')

    stack.save_image(img_MIP, name_save)
    api.log(name_save)

    # Preferred solution, but doesn't work yet. 
    # Bug in Jupyter: returned content-Type is "text/html" but should be "image/png"
    # Causes CORB error in Chrome.

    """
    file_url = await file_manager.getFileUrl({'path': name_save})
    api.log(file_url)
    return file_url, img_MIP.shape
    """
    
    # Workaround until content type is fixed
    with open(name_save, 'rb') as f:
        data = f.read()
        result = base64.b64encode(data).decode('ascii')
        url_base64 = 'data:image/png;base64,' + result
    
    return url_base64, img_MIP.shape
    

class ImJoyPlugin():

    async def setup(self):
        api.log('FQ-worker plugin initialized.')
        self.file_manager = await api.getFileManager(api.ENGINE_URL)
        self.cwd = Path.cwd() 
  
    def run(self, ctx):
        api.alert('Helper plugin without run function.')

    def get_engine_url(self):
        return api.ENGINE_URL

    async def save_settings(self, config):
        """
        Save settings as json file.
        """
        # Parameters
        api.log('\nFQ-worker [save_settings]: received data:')
        api.log(config)

        # Name to save settings
        name_save = config['name_settings']
        config.pop('name_settings')

        with open(name_save, 'w') as json_file:
            json.dump(config, json_file,indent=4, separators=(',', ': '))

        api.log(f'Settings file save as {name_save}')


    def scan_folder(self, config):
        """
        Scan folder for images to be analyzed.
        """

        api.showStatus('Scanning folder for images with specified configuration ... ')

        # Parameters
        api.log('\nFQ-worker [scan_folder]: received data:')
        api.log(config)
        channels  = config['channels']
        reg_exp   = config['reg_exp']
        path_data_full = Path(config['data_path'])

        # Get channels as dict
        ch_dict = {channel['identifier']: channel['name'] for channel in channels}
        ch_identifier = list(ch_dict.keys())

        # Scan all files create data-frame for files that match the regular expression
        api.log(f'FQ-worker [scan_folder]: {str(path_data_full)}')
        api.log(f'channels: {ch_dict}')
        api.log(f'reg_exp: {reg_exp}')

        df_regexp = pd.DataFrame()
        for file in os.listdir(str(path_data_full)):
            match = re.search(reg_exp, file)

            if match:
                match_dict = match.groupdict()
                match_dict.update({'file_name': file})
                df_regexp = df_regexp.append(match_dict, ignore_index=True)

        print(df_regexp.size)
        if df_regexp.size == 0:
            api.alert('No images with these specifications found.')
            return

        # Get unique positions (ignore channels)
        df_pos_unique = df_regexp.drop_duplicates(['file_ident', 'fov'])
        df_pos_unique = df_pos_unique.drop(columns=['channel', 'file_name'])

        # Iterate over the Dataframe rows as named tuples
        df_scan = pd.DataFrame()
        for pos_unique in df_pos_unique.itertuples(index=False):
            file_ident_loop = getattr(pos_unique, 'file_ident')
            fov_loop = getattr(pos_unique, 'fov')
            img_ext_loop = getattr(pos_unique, 'img_ext')

            # Find all channels of unique positions
            df_loop = df_regexp.query('(file_ident == @file_ident_loop) and (fov == @fov_loop)')
            channels_loop = df_loop['channel'].values.tolist()

            # Verify if all channels are present
            if set(ch_identifier) <= set(channels_loop):

                data_dict = pos_unique._asdict()

                # Find file-names for each channel and add to dictionary
                for ch_query in ch_identifier:
                    image_name = df_loop.query('channel == @ch_query')['file_name'].values[0]
                    data_dict.update({ch_dict[ch_query]: image_name})

                df_scan = df_scan.append(data_dict, ignore_index=True)

        self.path_data_full = path_data_full
        scan_results = df_scan.to_dict('records')
        api.showStatus(f'Found {len(scan_results)} images matching the search criteria.')
        api.log('\nFQ-worker [scan_folder]: scan results:')
        api.log(scan_results)
        
        return scan_results


    async def load_image(self,config):
        """
        Function to load image.
        """
        
        # Parameters
        api.log('\nFQ-worker [load_image]: received data:')
        api.log(config)
        show_status = config['show_status']
        if show_status: api.showStatus('Loading images. Please wait .... ')

        # Folder containing data
        path_data_full = self.path_data_full

        # Get channel names
        channels = config['channels']
        channel_identifiers = [channel['identifier'] for channel in channels]
        channel_names = [channel['name'] for channel in channels]
        ch_dict = {channel['name']: channel['identifier'] for channel in channels}

        # MIPs: create folder to store images
        if config['create_mips']:
            mips = []
            path_save = create_output_path(path_data_full, config['output_path']) / 'imjoy-tmp' / 'mips'
            create_folder(path_save)
            api.log(f'Folder for MIPs: {path_save}')

        # Loop over channels and build 5D tensor (starfish)
        tensors_3d = []
        tensors_4d = []
        image = []
        image_names = {}

        for index, channel_name in enumerate(channel_names):
            image_name = config['file'][channel_name]
            image_name_full = str(path_data_full / image_name)
            api.log(f'Reading image: {image_name_full}')

            tensor_3d = io.imread(image_name_full)
            tensors_3d.append(tensor_3d)

            image_names.update({ channel_name :  {
                                    'index': index,
                                    'image_name': image_name,
                                    'identifier': ch_dict[channel_name]
                                }
            })

            if config['create_mips']:
                name_save = str(path_save / f'img_mip_dum__{channel_name}.png')
                url, shape = await image_mip_url(tensor_3d, name_save, self.file_manager, rescale = True)
                mips.append({'url':url,'shape':shape,'channel':channel_name,'image_name':image_name})

        # stack 3-d tensors in 4-d
        tensor_4d = np.stack(tensors_3d, axis=0)
        tensors_4d.append(tensor_4d)

        # stack 4-d tensors in 5-d
        image = np.stack(tensors_4d, axis=0)
        api.log(f'FQ-worker [load_image]: loaded image: Shape: {image.shape}, dtype: {image.dtype}')

        self.image = image
        self.image_names = image_names
        self.image_size = image.shape

        self.image_filt = []
        self.mask_lm = []

        self.channel_identifiers = channel_identifiers
        self.channel_names = channel_name

        if show_status: api.showStatus('Image loaded!')

        # Return MIPs
        if config['create_mips']:
            return mips
    
    
    async def filter_image(self,config):
        """
        Filter selected image
        """

        # Parameters
        api.log('\nFQ-worker [filter_image]: received data:')
        api.log(config)

        sigma = config['sigma']
        channel_selected = config['channel_selected']
        show_status = config['show_status']
        path_data_full = self.path_data_full
        image_names = self.image_names

        if show_status: api.showStatus('Filtering image ....')

        # Is a sub-region selected?
        if 'selected_region' in config:
            selected_region = config['selected_region']
        else:
            selected_region = []

        # Check if channel was selected
        if len(channel_selected) == 0:
            api.alert('Please select which channel should be processed!')
            return

        # Get index of channel that will be analyzed
        channel_index = self.image_names[channel_selected]["index"]
        api.log(f'FQ-worker [filter_image]: filter channel {channel_selected} with index {channel_index}')

        # Crop image if specified
        x_min = None

        if selected_region:
            numbers = np.fromstring(selected_region,dtype=float, sep=',').astype('int')
            n_y = self.image.shape[3]-1
            n_x = self.image.shape[4]-1

            x_min = numbers[0]
            x_max = numbers[2]
            y_min = n_y-numbers[3]
            y_max = n_y-numbers[1]

            if (x_min<0): x_min = 0
            if (x_max>n_x): x_max = n_x
            if (y_min<0): x_min = 0
            if (y_max>n_y): y_max = n_y

  
        # Select image and filter
        if x_min:
            img = self.image[0, channel_index, :,y_min:y_max, x_min:x_max]
        else:
            img = self.image[0, channel_index, :, :, :]

        img_filt = stack.log_filter(img, sigma)
        self.image_filt = img_filt
        self.mask_lm = []
        self.channel_selected = channel_selected
        self.channel_index = channel_index

        # Create MIP and provide base64 encoded strings
        if config['create_mips']:
            path_save = create_output_path(path_data_full, config['output_path']) / 'imjoy-tmp' / 'mips'
            create_folder(path_save)
            
            name_save = str(path_save / f'img_filt_mip_dum_c{channel_index}.png')
            url,shape = await image_mip_url(img_filt, name_save, self.file_manager, rescale = True)

            # Return results
            if show_status: api.showStatus('Filtering finished!')
            return {'url':url,'shape':shape,'min':img_filt.min().item(),'max':img_filt.max().item()}  # .item() to convert to number


    def save_image_filtered(self,config):
        '''
        Save filtered image.
        '''

        # Parameters
        api.log('\nFQ-worker [save_image_filtered]: received data:')
        api.log(config)

        channel_selected = config['channel_selected']
        channel_name = self.image_names[channel_selected]["image_name"]
        
        path_save = create_output_path(self.path_data_full, config['output_path']) / 'images_filtered'
        create_folder(path_save)
        
        # Save image under original name in dedicated folder
        stack.save_image(self.image_filt, str(path_save / channel_name))
        api.alert(f'Filtered image saved as {channel_name}, \nin folder: {str(path_save)}')


    async def calc_local_max(self,config):
        '''
        Calculate local maximum image from filtered image.
        '''

        # Input parameters
        api.log('\nFQ-worker [calc_local_max]: received data:')
        api.log(config)
        minimum_distance = config['minimum_distance']

        # Local maximum detection
        self.mask_lm = detection.local_maximum_detection(self.image_filt, minimum_distance = minimum_distance)


    async def detect_test_thresholds(self,config):
        '''
        Perform detection

        TODO:
        * Re-use stored mask_lm if appropriate (same file, same settings, ...)
          Requires a bunch of checks ... same image, same min distance, ...
        '''

        # Parameters
        api.log('\nFQ-worker [filter_image]: received data:')
        api.log(config)
        sigma = config['sigma']
        threshold_range = config['threshold_range']
        show_status = config['show_status']

        if show_status: api.showStatus('Performing predection ... calculate local maximum image')

        # Calculate local maximum
        #if len(self.mask_lm)==0:
        await self.calc_local_max({ 'minimum_distance': config['minimum_distance']})

        # Loop over thresholds
        if show_status: api.showStatus('Performing predection ... testing thresholds')

        thresholds_spot = np.around(np.linspace(threshold_range[0], threshold_range[1],threshold_range[2] ))

        n_thresholds = threshold_range[2]
        n_detections = np.empty(n_thresholds,dtype='int')

        for i in range(n_thresholds):
            api.showProgress((i+1)/n_thresholds)
            threshold = thresholds_spot[i]
            spots, radius, _ = detection.spots_thresholding(self.image_filt, tuple(sigma), self.mask_lm, threshold)
            n_detections[i] = spots.shape[0]
            api.log(f'Testing threshold {i}/{n_thresholds}: {threshold}  ... {n_detections[i]} spots detected.')

        return [thresholds_spot.tolist(), n_detections.tolist()]


    async def detect_apply(self,config):
        '''
        Apply spot detection.
        Returns spots as a nested list [[Z0,Y0,X0],[Z1,Y1,X1], .... ]
        '''
        # Get parameters
        threshold = config['detection_threshold']
        sigma = config['sigma']
        show_status = config['show_status']

        spots, radius, _ = detection.spots_thresholding(self.image_filt, tuple(sigma), self.mask_lm, threshold)
        return spots.tolist()

    async def detection_file(self,config):
        '''
        Process all files with specified settings.
        '''

        # Parameters
        api.log('\nFQ-worker [detection_image]: received data:')
        api.log(config)
        channel_selected = config['channel_selected']
        channels = config['channels']

        # Some preparation
        path_save = create_output_path(self.path_data_full, config['output_path']) / 'spot_detection' 
        create_folder(path_save)
        ch_dict = {channel['name']: channel['identifier'] for channel in channels}
        
        # Filter
        api.showStatus(f'Processing file: filtering image')
        await self.filter_image({
                        'sigma': tuple(config['sigma']),
                        'channel_selected': channel_selected,
                        'create_mips': False,
                        'show_status': False
                        })

        # Detection
        api.showStatus(f'Processing file: spot detection')
        await self.calc_local_max({
                        'minimum_distance': config['minimum_distance'],
                        'show_status': False
                        })

        spots = await self.detect_apply({
                        'detection_threshold': config['detection_threshold'],
                        'sigma': tuple(config['sigma']),
                        'show_status': False
                        })

        # Save results
        image_name = self.image_names[channel_selected]["image_name"]
        name_base, file_extension = os.path.splitext(image_name)
        file_save = path_save / f'{name_base}__spots.csv'

        np.savetxt( file_save,
                    np.asarray(spots),
                    fmt='%i',
                    header="Z;Y;X", delimiter=';', comments='')
        api.log(f'\nFQ-worker [detection_image]: results saved as {file_save}')

        # Save settings for file
        ch_ident = ch_dict[channel_selected]
        config['name_settings'] = os.path.join(path_save, name_base + '__settings.json')
        config['image_size'] = self.image_size
        config['image_identifier'] = self.image_names

        await self.save_settings(config)

        api.showStatus('Batch processing finished!')


    async def detection_batch(self,config):
        '''
        Process all files with specified settings.
        '''

        # Parameters
        api.log('\nFQ-worker [detection_batch]: received data:')
        api.log(config)
        channel_selected = config['channel_selected']
        channels = config['channels']

        # Some preparation
        path_save = create_output_path(self.path_data_full, config['output_path']) / 'spot_detection' 
        create_folder(path_save)
        ch_dict = {channel['name']: channel['identifier'] for channel in channels}

        # Scan folder
        files_process = self.scan_folder(config)

        # Loop over all files
        for idx, file_process in enumerate(files_process):

            # Load image
            api.showProgress((idx+1)/len(files_process))
            api.showStatus(f'Processing file {idx+1} of {len(files_process)}: loading image')
            await self.load_image({
                            'file': file_process,
                            'channels': config['channels'],
                            'data_path': config['data_path'],
                            'output_path': config['output_path'],
                            'create_mips': False,
                            'show_status': False
                            })
            # Filter
            api.showStatus(f'Processing file {idx+1} of {len(files_process)}: filtering image')
            await self.filter_image({
                            'sigma': tuple(config['sigma']),
                            'channel_selected': channel_selected,
                            'create_mips': False,
                            'show_status': False
                            })

            # Detection
            api.showStatus(f'Processing file {idx+1} of {len(files_process)}: spot detection')
            await self.calc_local_max({
                            'minimum_distance': config['minimum_distance'],
                            'show_status': False
                            })

            spots = await self.detect_apply({
                            'detection_threshold': config['detection_threshold'],
                            'sigma': tuple(config['sigma']),
                            'show_status': False
                            })

            # Save results
            image_name = self.image_names[channel_selected]["image_name"]
            name_base, file_extension = os.path.splitext(image_name)
            file_save = path_save / f'{name_base}__spots.csv'

            np.savetxt( file_save,
                        np.asarray(spots),
                        fmt='%i',
                        header="Z;Y;X", delimiter=';', comments='')
            api.log(f'\nFQ-worker [detection_batch]: results saved as {file_save}')

            # Save settings for file
            ch_ident = ch_dict[channel_selected]
            config['name_settings'] = os.path.join(path_save, name_base + '__settings.json')
            config['image_size'] = self.image_size
            config['image_identifier'] = file_process

            await self.save_settings(config)

        api.showStatus('Batch processing finished!')

api.export(ImJoyPlugin())
</script>