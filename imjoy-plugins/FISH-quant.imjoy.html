<docs lang="markdown">
Python plugin performing analyze of smFISH images. 

__DEV NOTE__: with tag "dev" no requirements will be installed. Make sure that you have
big-fish installed in the env where you run this plugin. Either the stable version from 
`https://github.com/muellerflorian/big-fish@test-setup` or a local editable installation.
</docs>

TODO: update install link to fish-quant/big-fish once PR for pip installation is merged.

<config lang="json">
{
  "name": "FISH-QUANT",
  "type": "native-python",
  "version": "0.0.4",
  "description": "Worker to process smFISH images.",
  "tags": ["stable","dev"],
  "ui": "",
  "cover": "",
  "inputs": null,
  "outputs": null,
  "flags": ["single-instance", "allow-detach"],
  "icon": "extension",
  "api_version": "0.1.8",
  "env": "",
  "permissions": [],
  "requirements": { "stable":["pip: -U git+https://github.com/fish-quant/big-fish@master#egg=big-fish"],
                    "dev": [""]},
    "dependencies":  [
          "fish-quant/fq-imjoy:FQ-interface",
          ],
  "runnable": true
}
</config>

<script lang="python">

from imjoy import api
import asyncio
import sys
import os
from pathlib import Path
import json
import re
import base64
from datetime import datetime
import numpy as np
from skimage import io
import pandas as pd
from skimage.exposure import rescale_intensity

# For MAC
if sys.platform == "darwin":
    import matplotlib
    matplotlib.use('PS')


from bigfish import stack, plot, detection

# Is there a way to get the version without import?
import bigfish 


def log_config(fun_name, config):
    """
    log the config file, and remove larger elements to not clog the log
    """
    api.log(f'{fun_name} received data::')
    if 'detection_plot' in config:
        api.log('Detection plot present, but removed for display')
        del config['detection_plot']

    api.log(config)


def save_spots(spots, type, name_save):
    """
    Save results of spot detection.
    """
    if type == 'ZYX':
        header = "Z,Y,X"

    if type == 'ZYXF':
        header = "Z,Y,X,foci_idx"

    np.savetxt( name_save,
                np.asarray(spots),
                fmt='%i',
                header=header, 
                delimiter=',', 
                comments='')
    api.log(f'[FISH-QUANT][save_spots] results ({type} saved as: {name_save}')


def save_foci(foci, name_save):
    """
    Save results of spot detection.
    """

    header = "Z,Y,X,n_rna,index"

    np.savetxt( name_save,
                np.asarray(foci),
                fmt='%i',
                header=header, 
                delimiter=',', 
                comments='')
    api.log(f'[FISH-QUANT][save_foci] results ({type} saved as: {name_save}')


def save_encoded_plot(plot, name_save):
    """
    Save encoded plot as png.
    """
    header, img_encoded = plot.split(",", 1)
    img_decoded = base64.b64decode(img_encoded)
    with open(name_save, 'wb') as f:
        f.write(img_decoded)
    api.log(f'[FISH-QUANT][save_encoded_plot]: plot saved as {name_save}')


def show_png(name_img):
    """
    Show png image.
    """
    with open(name_img, 'rb') as f:
        data = f.read()
        result = base64.b64encode(data).decode('ascii')
        imgurl = 'data:image/png;base64,' + result
        #api.createWindow(type='imjoy/image', w=12, h=15, data={"src": imgurl})
        api.showDialog(type='imjoy/image', w=12, h=15, data={"src": imgurl})


def create_folder(path_new):
    """
    Check if path `path_new` exisist. If not, create it.
    """
    if not path_new.is_dir():
        path_new.mkdir(parents=True)


def create_output_path(data_path, output_path):
    """
    Function to determine correct output path.

    If the string output_path contains characters '>>' it will not
    be interpreted as a path name but as an indicator for a string
    replacement operation for the data_path: old_str>>new_str
    """
    
    # Make sure they are strings
    data_path = str(data_path)
    output_path = str(output_path)

    if (re.search(">>", output_path)):
      str_orig = re.search(r'^(.*)>>(.*)$', output_path).group(1)
      str_rep = re.search(r'^(.*)>>(.*)$', output_path).group(2)

      print(f'Replacement parameters found: original string: {str_orig}, replacement string: {str_rep}')

      output_path_return = data_path.replace(str_orig,str_rep)
      print(f'Output path: {output_path_return}')

    else:
      print("No match")
      output_path_return = output_path

    # Convert back to Path
    output_path_return = Path(output_path_return)
    create_folder(output_path_return)

    return output_path_return


async def image_mip(img, name_save, file_manager, create_url=False, rescale=True):
    """
    Provide a base64 encoded URL of a MIP.
    """
    img_mip = stack.maximum_projection(img)

    #await api.showDialog(type='ImageViewer', name="Show image with ImageViewer", data={"image_array": img_mip})

    # Create URL for image to be shown in interface
    if create_url:

        # Rescale image (only required when creating url)
        if rescale:
            pa, pb = np.percentile(img_mip, (0.1,99.9))
            img_mip_save = rescale_intensity(img_mip, in_range=(pa, pb),out_range=np.uint8).astype('uint8')
        else:
            img_mip_save = np.copy(img_mip)

        stack.save_image(img_mip_save, name_save)
        api.log(f'[FISH-QUANT][image_mip] mip saved as: {name_save}')

        # Preferred solution, but doesn't work yet. 
        # Bug in Jupyter: returned content-Type is "text/html" but should be "image/png"
        # Causes CORB error in Chrome.

        """
        img_url = await file_manager.getFileUrl({'path': name_save})
        api.log(file_url)
        return img_mip, img_mip.shape, file_url
        """
    
        # Workaround until content type is fixed
        with open(name_save, 'rb') as f:
            data = f.read()
            result = base64.b64encode(data).decode('ascii')
            img_url = 'data:image/png;base64,' + result
    
    else:
        img_url = None
    
    return img_mip, img_mip.shape, img_url
    

class ImJoyPlugin():

 
    async def setup(self):
        api.log('[FISH-QUANT] plugin initialized.')
        self.file_manager = await api.getFileManager(api.FILE_MANAGER_URL)
        self.cwd = Path.cwd() 
        self.analysis_details = {
                'date': '',
                'data_specs': {},
                'image_properties': {},
                'spot_detection': {'counts': {},
                                  'settings' :{}
                                   }
        }
                

    async def run(self, ctx):
        self.FQ_interface = await api.createWindow(type="FQ-interface",
                                                   name='FISH-quant',
                                                   data={'file_manager': api.FILE_MANAGER_URL,
                                                         'engine_url': api.ENGINE_URL,
                                                         'version_FQ': await api.getConfig('_version'),
                                                         'version_bigfish': bigfish.__version__})

    def get_engine_url(self):
        return api.ENGINE_URL

    async def select_analysis_region(self, config):
        """
        Show results (images, spots, outlines, ...)
        """

        # Parameters
        log_config('[FISH-QUANT][select_analysis_region]', config)
        channel_selected = config['channel_selected']
        display_type = config['display_type']

        # Show image
        # Could also be viewer = await api.createWindow(type="Kaibu")

        if display_type == 'window':
            viewer = await api.createWindow(src="https://kaibu.org")
    
        elif display_type == 'dialog':
            viewer = await api.showDialog(src="https://kaibu.org")
    
        # Check if channel was selected
        if len(channel_selected) == 0:
            api.alert('Please select which channel should be processed!')
            return

        # Get index of selected channel
        channel_index = self.image_names[channel_selected]["index"]
        api.log(f'channel_index: {channel_index}')
        
        # Create viewer
        image_array = self.image_mips[channel_index, :, :]
        await viewer.view_image(image_array, type="itk-vtk", name='image')

        # Add annotation layer
        layer = await viewer.add_shapes([ ], shape_type="polygon", edge_color="red", name="analysis region", draw_shape_type= "Rectangle",draw_enable=True)

        # get the annotation in geojson format

        async def get_geojson_features():    
            features = await layer.get_features()
 
            if len(features['features']) != 1:
                api.alert('Only one annotation is allowed')
                return

            if features['features'][0]['geometry']['type'] != 'Polygon':
                api.alert('Annotation has to be a Polygon')
                return

            coords = np.asarray(features['features'][0]['geometry']['coordinates'][0])
            if len(coords) != 5:
                api.alert('This is not a rectangular selection')
                return

            analysis_region = np.around(np.concatenate((coords.min(axis=0),coords.max(axis=0))))
            
            self.analysis_region = analysis_region.astype('uint16')
            viewer.close 

        await viewer.set_ui({"title": "Utilities",
                    "elements": [
                        {"_rintf": True,
                        "type": "button",
                        "label": "Return selection to FISH-quant",
                        "callback": get_geojson_features
                        },   
                    ]
        })    

    async def show_results(self, config):
        """
        Show results (images, spots, outlines, ...)
        """

        # Parameters
        log_config('[FISH-QUANT][show_results]', config)
        display_type = config['display_type']
        data_show = config['data_show']

        # Show image
        # Could also be viewer = await api.createWindow(type="Kaibu")

        if display_type == 'window':
            viewer = await api.createWindow(src="https://kaibu.org")
  
        elif display_type == 'dialog':
            viewer = await api.showDialog(src="https://kaibu.org")
   
        # Loop over provided layers that should be displayed
        for data_add in data_show:
            api.log(f'Adding new layer with specs: {data_add}')

            data_type = data_add[0]

            # Raw or filtered image
            if data_type == 'img_raw' or data_type == 'img_filt':
                
                channel_selected = data_add[1]
                display_dim = data_add[2]
                visible = data_add[3]
                
                if visible == 'true':
                    visible = True
                else:
                    visible = False

                # Check if channel was selected
                if len(channel_selected) == 0:
                    api.alert('Please select which channel should be processed!')
                    return

                # Get index of selected channel
                channel_index = self.image_names[channel_selected]["index"]
                api.log(f'channel_index: {channel_index}; image_type: {data_type}; display_dim: {display_dim};')
                
                # Get image to be shown
                if data_type == 'img_raw':
                    name = 'raw image'
                        
                    # Full image
                    if self.filter_full:
            
                        if display_dim == 'orig':
                            image_array = self.image[0, channel_index, :, :, :]
                    
                        elif display_dim == 'mip':
                            image_array = self.image_mips[channel_index, :, :]
                    
                    # Croppend image for analysis
                    else:
                        
                        if display_dim == 'orig':
                            image_array = self.image_raw
                    
                        elif display_dim == 'mip':
                            image_array = self.image_raw_mip

                elif data_type == 'img_filt':
                    name = 'filtered image'
                    if display_dim == 'orig':
                        image_array = self.image_filt

                    elif display_dim == 'mip':
                        image_array = self.image_filt_mip

                await viewer.view_image(image_array, type="itk-vtk", name=name, visible=visible)

            elif data_type == 'spots' or data_type == 'spots_decompose':
                
                size=data_add[1]
                visible = data_add[2]

                if visible == 'true':
                    visible = True
                else:
                    visible = False

                if data_type == 'spots':
                    points=self.spots.astype('uint16')
                else:
                    points=self.spots_post_decomposition.astype('uint16')

                # Remove z position if present 
                if points.shape[1] == 3:
                    points = np.delete(points, 0, 1)
                
                # Invert X and Y 
                points[:,[0, 1]] = points[:,[1, 0]]
                
                await viewer.add_points(points, size=size, name='Detections', visible=visible, edge_color = '#db2307', face_color = '#eb9d91')


    async def save_analysis_details(self, name_save):
        """
        Save settings as json file.
        """
        # Parameters
        api.log('[FISH-QUANT][save_analysis_details]')

        # Add more fields
        now = datetime.now() # current date and time
        self.analysis_details['date'] = now.strftime("%d/%m/%Y__%H:%M:%S")

        # Save as json
        with open(name_save, 'w') as json_file:
            json.dump(self.analysis_details, json_file,indent=4, separators=(',', ': '))

        api.log(f'[FISH-QUANT][save_analysis_details] saved as {name_save}')


    def scan_folder(self, config):
        """
        Scan folder for images to be analyzed.
        """

        api.showStatus('Scanning folder for images with specified configuration ... ')

        # Parameters
        log_config('[FISH-QUANT][scan_folder]', config)
        channels  = config['channels']
        reg_exp   = config['reg_exp']
        path_data_full = Path(config['data_path'])
        
        if not path_data_full.is_dir():
            api.alert('Specified data path does not EXIST. No images found.')
            return

        # Get channels as dict
        ch_dict = {channel['identifier']: channel['name'] for channel in channels}
        ch_identifier = list(ch_dict.keys())
        api.log(f'[FISH-QUANT][scan_folder] channel dictionary: {ch_dict}')

        # Scan all files create data-frame for files that match the regular expression
        df_regexp = pd.DataFrame()

        for file in os.listdir(str(path_data_full)):
            match = re.search(reg_exp, file)

            if match:
                match_dict = match.groupdict()

                # Add only if image extension matches
                if match_dict['img_ext'] == config['img_ext']:
                    match_dict.update({'file_name': file})
                    df_regexp = df_regexp.append(match_dict, ignore_index=True)

        if df_regexp.size == 0:
            api.alert('No images with these specifications found.')
            return

        # Get unique positions (ignore channels)
        df_pos_unique = df_regexp.drop_duplicates(['file_ident', 'fov'])
        df_pos_unique = df_pos_unique.drop(columns=['channel', 'file_name'])

        # Iterate over the Dataframe rows as named tuples
        df_scan = pd.DataFrame()
        for pos_unique in df_pos_unique.itertuples(index=False):
            file_ident_loop = getattr(pos_unique, 'file_ident')
            fov_loop = getattr(pos_unique, 'fov')
           
            # Find all channels of unique positions
            df_loop = df_regexp.query('(file_ident == @file_ident_loop) and (fov == @fov_loop)')
            channels_loop = df_loop['channel'].values.tolist()

            # Verify if all channels are present
            if set(ch_identifier) <= set(channels_loop):

                data_dict = pos_unique._asdict()

                # Find file-names for each channel and add to dictionary
                for ch_query in ch_identifier:
                    image_name = df_loop.query('channel == @ch_query')['file_name'].values[0]
                    data_dict.update({ch_dict[ch_query]: image_name})

                df_scan = df_scan.append(data_dict, ignore_index=True)

        self.path_data_full = path_data_full
        scan_results = df_scan.to_dict('records')
        api.showStatus(f'Found {len(scan_results)} images matching the search criteria.')
        api.log('[FISH-QUANT][scan_folder] scan results:')
        api.log(scan_results)
        
        # Save analysis details
        self.analysis_details['data_specs']['data_path'] = str(path_data_full)
        self.analysis_details['data_specs']['channels'] = channels
        self.analysis_details['data_specs']['reg_exp'] = reg_exp

        return scan_results


    async def load_image(self,config):
        """
        Function to load image.
        """
        
        log_config('[FISH-QUANT][load_image]', config)

        show_status = config['show_status']
        if show_status: api.showStatus('Loading images. Please wait .... ')

        # Folder containing data
        path_data_full = self.path_data_full

        # Output path
        self.path_analysis = create_output_path(path_data_full, config['output_path'])
        create_folder(self.path_analysis)

        # Get channel names
        channels = config['channels']
        channel_identifiers = [channel['identifier'] for channel in channels]
        channel_names = [channel['name'] for channel in channels]
        ch_dict = {channel['name']: channel['identifier'] for channel in channels}

        # MIPs: create folder to store images
        if config['create_mips']:
            mips = []
            path_save = self.path_analysis / 'imjoy-tmp' / 'mips'
            create_folder(path_save)
            api.log(f'[FISH-QUANT][load_image] path for MIPs: {path_save}')

        # Loop over channels and build 5D tensor (starfish)
        tensors_3d = []
        tensors_4d = []
        mip_tensors = []
        image_names = {}

        for index, channel_name in enumerate(channel_names):
            image_name = config['file'][channel_name]
            image_name_full = str(path_data_full / image_name)
            api.log(f'[FISH-QUANT][load_image] reading image: {image_name_full}')

            tensor_3d = io.imread(image_name_full)
            tensors_3d.append(tensor_3d)

            image_names.update({ channel_name :  {
                                    'index': index,
                                    'image_name': image_name,
                                    'identifier': ch_dict[channel_name]
                                }
            })

            if config['create_mips']:
                name_save = str(path_save / f'img_mip_dum__{channel_name}.png')
                img_mip, shape, url = await image_mip(tensor_3d, name_save, self.file_manager, create_url=True, rescale=True)

                mip_tensors.append(img_mip)
                mips.append({'url':url,'shape':shape,'channel':channel_name,'image_name':image_name})

        # stack 3-d tensors in 4-d
        tensor_4d = np.stack(tensors_3d, axis=0)
        tensors_4d.append(tensor_4d)

        # stack 4-d tensors in 5-d
        image = np.stack(tensors_4d, axis=0)
        
        # Save some image properties
        self.analysis_details['data_specs']['output_path'] = config['output_path']
        self.analysis_details['image_properties']['image_names'] = image_names
        self.analysis_details['image_properties']['size'] = image.shape

        # Store for later usage
        self.image = image
        self.image_names = image_names
        self.channel_identifiers = channel_identifiers
        self.channel_names = channel_name

        # Initiate some parameters that will be populated along the way
        self.image_filt = []
        self.mask_lm = []
        self.analysis_region = []

        # Status updates
        api.log(f'[FISH-QUANT][load_image] loaded image: shape: {image.shape}, dtype: {image.dtype}')
        if show_status: api.showStatus('Image loaded!')

        # Return MIPs
        if config['create_mips']:
            self.image_mips = np.stack(mip_tensors, axis=0)
            return mips
    

    async def filter_image(self,config):
        """
        Filter selected image
        """

        # Parameters
        log_config('[FISH-QUANT][filter_image]', config)
        sigma = config['sigma']
        channel_selected = config['channel_selected']
        show_status = config['show_status']
        path_data_full = self.path_data_full
        image_names = self.image_names

        if show_status: api.showStatus('Filtering image ....')

        # Get index of channel that will be analyzed
        channel_index = image_names[channel_selected]["index"]
        api.log(f'[FISH-QUANT][filter_image] filtering channel {channel_selected} with index {channel_index}')

        # Crop image if specified
        x_min = None
        
        if len(self.analysis_region) > 0:
            analysis_region = self.analysis_region

            n_y = self.image.shape[3]-1
            n_x = self.image.shape[4]-1

            x_min = analysis_region[0]
            y_min = analysis_region[1]
            x_max = analysis_region[2]
            y_max = analysis_region[3]
   
            if (x_min<0): x_min = 0
            if (x_max>n_x): x_max = n_x
            if (y_min<0): x_min = 0
            if (y_max>n_y): y_max = n_y
        
            img = self.image[0, channel_index, :,y_min:y_max, x_min:x_max]
            self.image_raw = img
            self.image_raw_mip = stack.maximum_projection(img)
            self.filter_full = False
        
        else:
            img = self.image[0, channel_index, :, :, :]
            self.filter_full = True        

        # Check if channel was selected
        if len(channel_selected) == 0:
            api.alert('Please select which channel should be processed!')
            return

        img_filt = stack.log_filter(img, sigma)

        # Get name-base of loaded image
        image_name = image_names[channel_selected]["image_name"]
        name_base, file_extension = os.path.splitext(image_name)

        self.image_filt = img_filt
        self.mask_lm = []
        self.channel_selected = channel_selected
        self.channel_index = channel_index
        self.name_base = name_base

        # Save settings of spot detection
        self.analysis_details['spot_detection']['settings']['filter'] = {
            'method' : 'LoG',
            'sigma': sigma
        }

        # Save some image properties
        self.analysis_details['image_properties']['channel_selected'] = channel_selected
        self.analysis_details['image_properties']['intensity'] = {
            'raw_mean': np.mean(img),
            'raw_median': np.median(img),
            'raw_std': np.std(img),
            'filt_mean': np.mean(img_filt),
            'filt_median': np.median(img_filt),
            'filt_std': np.std(img_filt),
        }

        # Create MIP and provide base64 encoded strings
        if config['create_mips']:
            path_save = self.path_analysis / 'imjoy-tmp' / 'mips'
            create_folder(path_save)
            
            name_save = str(path_save / f'img_filt_mip_dum_c{channel_index}.png')
            img_mip, shape, url = await image_mip(img_filt, name_save, self.file_manager, create_url=True, rescale=True)

            self.image_filt_mip = img_mip
            if show_status: api.showStatus('Filtering finished!')
            return {'url':url,'shape':shape,'min':img_filt.min().item(),'max':img_filt.max().item()}  # .item() to convert to number


    def save_image_filtered(self,config):
        '''
        Save filtered image.
        '''
        # TODO: supported is only png, tif, tiff
        
        # Parameters
        log_config('[FISH-QUANT][save_image_filtered]', config)
        channel_selected = config['channel_selected']
        channel_name = self.image_names[channel_selected]["image_name"]
        
        path_save = self.path_analysis / 'images_filtered'
        create_folder(path_save)
        
        # Save image under original name in dedicated folder
        stack.save_image(self.image_filt, str(path_save / channel_name))
        api.alert(f'Filtered image saved as {channel_name}, \nin folder: {str(path_save)}')


    async def calc_local_max(self, config):
        '''
        Calculate local maximum image from filtered image.
        '''

        # Parameters
        log_config('[FISH-QUANT][calc_local_max]', config)
        minimum_distance = config['minimum_distance']
        sigma = (minimum_distance[1], minimum_distance[0], minimum_distance[0])

        # Local maximum detection
        self.mask_lm = detection.local_maximum_detection(self.image_filt, sigma)

        # Settings
        self.analysis_details['spot_detection']['settings']['detection'] = {
            'method': 'localmax',
            'mind_dist': minimum_distance
        }

    async def detect_test_thresholds(self,config):
        '''
        Perform detection

        TODO:
        * Re-use stored mask_lm if appropriate (same file, same settings, ...)
          Requires a bunch of checks ... same image, same min distance, ...
        '''

        # Parameters
        log_config('[FISH-QUANT][detect_test_thresholds]', config)
        threshold_range = config['threshold_range']
        show_status = config['show_status']

        if show_status: api.showStatus('Performing predection ... calculate local maximum image')

        # Calculate local maximum
        #if len(self.mask_lm)==0:
        await self.calc_local_max({ 'minimum_distance': config['minimum_distance']})

        # Loop over thresholds
        if show_status: api.showStatus('Performing predection ... testing thresholds')
        self.FQ_interface.emit('create_detection_plot',[])
        thresholds_spot = np.around(np.linspace(threshold_range[0], threshold_range[1],threshold_range[2] ))

        n_thresholds = threshold_range[2]
        n_detections = np.zeros(n_thresholds,dtype='int')

        for i in range(n_thresholds):
            api.showProgress((i+1)/n_thresholds)
            threshold = thresholds_spot[i]
            spots, _ = detection.spots_thresholding(self.image_filt, self.mask_lm, threshold)
            n_detections[i] = spots.shape[0]
            api.log(f'[FISH-QUANT][detect_test_thresholds] testing threshold {i}/{n_thresholds}: {threshold}  yields  {n_detections[i]}  spots.')

            self.FQ_interface.emit('extend_detection_plot', [thresholds_spot[i].tolist(), n_detections[i].tolist()])

        if show_status: api.showStatus('Performing predection ... finished!')

        return [thresholds_spot.tolist(), n_detections.tolist()]


    async def detect_apply(self,config):
        ''' 
        Apply spot detection.
        Returns spots as a nested list [[Z0,Y0,X0],[Z1,Y1,X1], .... ]. 
        Why return? Can then be used to display in calling plugin.
        '''
        # Parameters
        log_config('[FISH-QUANT][detect_apply]', config)
        threshold = config['detection_threshold']
        show_status = config['show_status']
        
        # Save detection plot
        if 'detection_plot' in config:
            self.detection_plot = config['detection_plot']

        # Save image with position of detections
        if 'name_save' in config:
            name_save = config['name_save']
        else:
            name_save = None

        # Perform pre-detection
        spots, _ = detection.spots_thresholding(self.image_filt, self.mask_lm, threshold)

        # Save analysis details
        self.analysis_details['spot_detection']['settings']['detection']['threshold'] = threshold
        self.analysis_details['spot_detection']['counts'] = {
            'spots': len(spots)
        }

        # Save image with detections
        if name_save:
            image_contrasted = stack.rescale(self.image_filt, channel_to_stretch=0)
            image_contrasted = stack.maximum_projection(image_contrasted)
            plot.plot_detection(image_contrasted, spots, radius=2, framesize=(10, 8), remove_frame=True,path_output=name_save)

        api.log(f'[FISH-QUANT][detect_apply] detection with threshold {threshold} detects {len(spots)} spots.')  
        api.showStatus(f'Detection with threshold {threshold} detects {len(spots)} spots.')
        self.spots = spots
        #return spots.tolist()


    async def decompose_clusters(self,config):
        """
        Decompose clusters.
        For more details see bigfish: detection.decompose_cluster
        """
        # Parameters
        log_config('[FISH-QUANT][decompose_clusters]', config)
        show_status = config['show_status']
  
        # Get image
        if not self.filter_full:
            img = self.image_raw 
        else:
            img = self.image[0, self.channel_index, :, :, :]
        
        spots_post_decomposition, clusters, reference_spot = detection.decompose_cluster(
            img, 
            spots=self.spots, 
            voxel_size_z = config['voxel_size_z'], 
            voxel_size_yx = config['voxel_size_yx'],
            psf_z = config['psf_size_z'], 
            psf_yx = config['psf_size_xy'], 
            alpha = config['cluster_alpha'], 
            beta = config['cluster_beta'])

        api.log(f'[FISH-QUANT][decompose_cluster] from {len(self.spots)} to {len(spots_post_decomposition)} spots.')
        api.showStatus(f'Cluster decomposition: from {len(self.spots)} to {len(spots_post_decomposition)} spots.')

        self.spots_post_decomposition = spots_post_decomposition
        #return spots_post_decomposition.tolist()


    async def detect_foci(self,config):
        """
        Detect foci.
        For more details see bigfish: detection.detect_foci
        """
        # Parameters
        log_config('[FISH-QUANT][detect_foci]', config)
        name_save = config['name_save']

        # Generate name for temporary image
        if name_save == 'tmp':
            name_base = self.name_base
            path_save = self.path_analysis / 'imjoy-tmp' 
            create_folder(path_save)
            name_save = str(path_save / f'{name_base}__foci_calling')

        # Detect foci
        spots_post_clustering, foci = detection.detect_foci(
            spots =  self.spots_post_decomposition, 
            voxel_size_z = config['voxel_size_z'], 
            voxel_size_yx = config['voxel_size_yx'],
            radius = config['foci_radius'], 
            nb_min_spots = config['foci_nb_min_spots'])

        api.log(f'[FISH-QUANT][detect_foci] found {len(foci)} foci for {len(self.spots_post_decomposition)} spots')
        
        self.spots_post_clustering = spots_post_clustering
        self.foci = foci

        # Save image with detections
        if name_save:

            # Create contrasted image
            image_contrasted = stack.rescale(self.image_filt, channel_to_stretch=0)
            image_contrasted = stack.maximum_projection(image_contrasted)

            # Consider entire image as a cell
            fov_results = stack.extract_cell(
                cell_label=np.ones(image_contrasted.shape).astype('uint8'),   # Consider entire image as a cell
                ndim=3, 
                rna_coord=spots_post_clustering, 
                others={"foci": foci},
                image=image_contrasted,
                remove_cropped_cell=False)

            # Plot image as one cell with foci
            plot.plot_cell(
                ndim=3, 
                cell_coord=fov_results[0]["cell_coord"],  
                rna_coord=fov_results[0]["rna_coord"], 
                foci_coord=fov_results[0]["foci"],  
                image=image_contrasted, 
                cell_mask=fov_results[0]["cell_mask"],  
                title="", 
                remove_frame=True, framesize=(10, 8),
                path_output=name_save,
                ext = 'png',
                show = False)

            api.log(f'[FISH-QUANT][detect_foci] foci plot saved as {name_save}.png')

        if config['show_status']:
            show_png(name_save+'.png')

        self.analysis_details['spot_detection']['settings']['foci_decomposition'] = {
            'nb_min_spots': config['foci_nb_min_spots'],
            'radius': config['foci_radius'],
            'voxel_size_z': config['voxel_size_z'],
            'voxel_size_yx': config['voxel_size_yx'],
            'psf_size_z': config['psf_size_z'],
            'psf_size_xy': config['psf_size_xy'],
            'cluster_alpha': config['cluster_alpha'],
            'cluster_beta': config['cluster_beta']
        }

        self.analysis_details['spot_detection']['counts']['spots_decomposed'] = len(self.spots_post_decomposition)
        self.analysis_details['spot_detection']['counts']['foci'] = len(foci)

        return spots_post_clustering.tolist(), foci.tolist()


    async def detection_file(self,config):
        '''
        Process all files with specified settings.
        '''

        # Parameters
        log_config('[FISH-QUANT][detection_file]', config)
        name_base = self.name_base

        # Path to save results
        path_save = self.path_analysis / 'spot_detection' 
        create_folder(path_save)

        if config['create_plots']:
            path_plots_detection = self.path_analysis / 'spot_detection' / 'plots_detection'
            create_folder(path_plots_detection)

            if config['analyze_clusters']:
                path_plots_foci = self.path_analysis / 'spot_detection' / 'plots_foci'
                create_folder(path_plots_foci)

        # Change parts of the config to process entire file
        config['create_mips'] = False
        config['show_status'] = False
        config['analysis_region'] = []  # Reset analysis region to analyze full size image

        # >>> Check if full size image has been processed already - if yes, filtering and local max can be reused
        if not self.filter_full:

            # Filter
            api.showStatus(f'Processing file: filtering image')
            await self.filter_image(config)
        
            # Detection
            api.showStatus(f'Processing file: spot detection')
            await self.calc_local_max(config)

        # >>> SPOT DETECTION

        # Apply spot detection
        if config['create_plots']:
            config['name_save'] = str(path_plots_detection / f'{name_base}__detection.png')
        else:
            config['name_save'] = False

        spots = await self.detect_apply(config)
   
        # Save spot positions
        save_spots(spots, 'ZYX',  path_save / f'{name_base}__spots.csv')

        # Save detection plot (if present)
        if hasattr(self, 'detection_plot'): 
            save_encoded_plot(self.detection_plot, path_save / f'{name_base}__detection_tests.png')

        # >>> Cluster decomposition
        if config['analyze_clusters']:
            await self.decompose_clusters(config)

            if config['create_plots']:
                config['name_save'] = str(path_plots_foci / f'{name_base}__foci_calling')
            else:
                config['name_save'] = False

            spots_post_clustering, foci = await self.detect_foci(config)
            
            save_spots(spots_post_clustering, 'ZYXF',  path_save / f'{name_base}__spots_foci.csv')
            save_foci(foci,  path_save / f'{name_base}__foci.csv')

        # >>> Save analysis details
        await self.save_analysis_details(path_save / f'{name_base}__analysis_details.json')

        # Update status
        det_th = config['detection_threshold']
        if not config['batch_analysis']:
            api.alert(f'Processing of loaded file finished:\n{name_base}\nDetection with threshold {det_th} yields  {len(spots)} spots')
        api.showStatus(f'Processing of loaded file finished: {len(spots)} spots detected')


    async def detection_batch(self,config):
        '''
        Process all files with specified settings.
        '''

        # Parameters
        log_config('[FISH-QUANT][detection_batch]', config)

        # Some preparation
        path_save = self.path_analysis / 'spot_detection' 
        create_folder(path_save)
  
        # Set some parameters in config for batch processing        
        config['create_mips'] = False
        config['show_status'] = False
        config['analysis_region'] = []  # Reset analysis region to analyze full size image

        # Scan folder
        files_process = self.scan_folder(config)

        # Loop over all files
        for idx, file_process in enumerate(files_process):

            # Load image
            api.showProgress((idx+1)/len(files_process))
            api.showStatus(f'Processing file {idx+1} of {len(files_process)}: loading image')
            config['file'] = file_process
            await self.load_image(config)
            self.filter_full = False
            name_base = self.name_base

            # Process file
            await self.detection_file(config)

        api.alert('Batch processing finished!')
        api.showStatus('Batch processing finished!')


api.export(ImJoyPlugin())
</script>
